# ğŸ“Š Telco Customer Churn Prediction

## End-to-End Machine Learning System for Retention Intelligence**

An end-to-end **customer churn prediction and analytics system** designed to identify **at-risk customers**, uncover **root churn drivers**, and enable **proactive retention strategies**.

Built on the **IBM Telco Customer Churn dataset**, this project reflects **real-world telecom churn workflows**, from data ingestion and modeling to explainability and deployment readiness.

---

## ğŸš€ Business Context

Customer churn has a **direct and measurable impact on revenue**.
In subscription businesses, **retaining an existing customer is far cheaper than acquiring a new one**.

### ğŸ¯ Core Business Question

> **Which customers are most likely to churn â€” and what actions can prevent it?**

### ğŸ¯ Business Objectives

* Predict churn with **high recall** to minimize missed at-risk customers
* Identify **behavioral, service, and contract-based churn drivers**
* Support **targeted, data-driven retention campaigns**

---

## ğŸ§¾ Dataset Overview

Each record represents one customer, with demographic, service usage, contract, and billing information.

### ğŸ‘¥ Demographics

* `gender`
* `SeniorCitizen`
* `Partner`
* `Dependents`

### ğŸ”§ Services

* `PhoneService`, `MultipleLines`
* `InternetService`
* `OnlineSecurity`, `OnlineBackup`
* `DeviceProtection`, `TechSupport`
* `StreamingTV`, `StreamingMovies`

### ğŸ’³ Account & Billing

* `tenure`
* `Contract`
* `PaymentMethod`
* `PaperlessBilling`
* `MonthlyCharges`
* `TotalCharges`

### ğŸ¯ Target

* **`Churn`** (Yes / No)

---

## ğŸ—‚ï¸ Project Structure (Production-Ready)

```text
customer-churn-prediction/
â”‚
â”œâ”€â”€ artifacts/                  # Model evaluation outputs
â”‚   â”œâ”€â”€ evaluation_metrics.json
â”‚   â”œâ”€â”€ classification_report.csv
â”‚   â”œâ”€â”€ confusion_matrix.csv
â”‚   â”œâ”€â”€ decile_lift.csv
â”‚   â””â”€â”€ roc_auc.txt
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Original dataset
â”‚   â””â”€â”€ processed/              # Cleaned & engineered datasets
â”‚
â”œâ”€â”€ models/                     # Trained models & pipelines
â”‚   â”œâ”€â”€ churn_pipeline.joblib
â”‚   â”œâ”€â”€ churn_model.joblib
â”‚   â”œâ”€â”€ feature_columns.joblib
â”‚   â””â”€â”€ training_metrics.json
â”‚
â”œâ”€â”€ notebooks/                  # Exploratory & modeling notebooks
â”‚   â”œâ”€â”€ 01_data_understanding.ipynb
â”‚   â”œâ”€â”€ 02_eda.ipynb
â”‚   â”œâ”€â”€ 03_feature_engineering.ipynb
â”‚   â””â”€â”€ 04_model_training.ipynb
â”‚
â”œâ”€â”€ src/                        # Production scripts
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ predict.py
â”‚
â”œâ”€â”€ reports/figures/             # EDA & insights visuals
â”‚
â”œâ”€â”€ api/                        # FastAPI inference service
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ ARCHITECTURE.md
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Tech Stack

* **Language:** Python
* **Data:** Pandas, NumPy
* **Visualization:** Matplotlib, Seaborn
* **Modeling:**

  * Logistic Regression
  * Decision Tree
  * Random Forest
  * XGBoost
  * LightGBM
  * CatBoost
* **Imbalance Handling:** Class weighting / SMOTE
* **Explainability:** SHAP
* **Deployment:** FastAPI
* **Version Control:** Git, GitHub

---

## ğŸ”¬ Methodology

### 1ï¸âƒ£ Data Cleaning

* Corrected data types (e.g., `TotalCharges`)
* Handled missing values
* Standardized categorical labels

### 2ï¸âƒ£ Exploratory Data Analysis

* Overall churn distribution
* Churn vs tenure, contract type, charges
* Identification of **high-risk customer segments**

### 3ï¸âƒ£ Feature Engineering

* Binary encoding (Yes/No)
* One-hot encoding for multi-class features
* Derived tenure & billing features

### 4ï¸âƒ£ Modeling Strategy

* **Baseline:** Logistic Regression, Decision Tree
* **Advanced:** Random Forest, XGBoost, LightGBM, CatBoost
* Class imbalance handled via **weighted loss / SMOTE**

### 5ï¸âƒ£ Evaluation Metrics

* ROC-AUC
* Precision, Recall, F1-Score
* Confusion Matrix

ğŸ“Œ **Primary business metric:** **Recall (Churn class)**

### 6ï¸âƒ£ Explainability

* SHAP global feature importance
* Individual customer-level explanations

---

## ğŸ“ˆ Key Insights

### ğŸ”‘ Top Churn Drivers

* Month-to-month contracts
* High monthly charges
* Lack of TechSupport & OnlineSecurity
* Low customer tenure

### ğŸ’¡ Insight

Customers with **short tenure**, **high bills**, and **no support services** exhibit the **highest churn probability**.

---

## ğŸ’¼ Business Recommendations

* Incentivize **contract upgrades** for month-to-month users
* Bundle **TechSupport & Security services**
* Offer **loyalty discounts** for long-tenure customers
* Trigger **targeted retention campaigns** using churn scores

---

## â–¶ï¸ How to Run (Step-by-Step)

### 1ï¸âƒ£ Clone the Repository

```bash
git clone <your-repo-url>
cd customer-churn-prediction
```

### 2ï¸âƒ£ Create Environment & Install Dependencies

```bash
pip install -r requirements.txt
```

---

### 3ï¸âƒ£ Run the Analysis (Recommended Order)

```text
01_data_understanding.ipynb
02_eda.ipynb
03_feature_engineering.ipynb
04_model_training.ipynb
```

---

### 4ï¸âƒ£ Train Model via Script (Production)

```bash
python src/train.py
```

Outputs:

* Trained model â†’ `models/`
* Evaluation artifacts â†’ `artifacts/`

---

### 5ï¸âƒ£ Run Predictions

```bash
python src/predict.py
```

---

### 6ï¸âƒ£ Run API (Optional â€“ Deployment Ready)

```bash
uvicorn api.main:app --reload
```

Open:

```
http://127.0.0.1:8000/docs
```

---

## ğŸ”® Future Enhancements

* Cost-sensitive churn optimization
* Customer Lifetime Value (CLV) modeling
* Uplift modeling for retention actions
* Streamlit executive dashboard
* Cloud deployment (Docker + AWS/GCP)

---

## ğŸ‘©â€ğŸ’» Author

**Priya Choure**
Data Science & Artificial Intelligence Practitioner
