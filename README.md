# ğŸ“Š Telco Customer Churn Prediction

An **end-to-end machine learning project** that predicts customer churn and uncovers **key business drivers** behind churn to support **data-driven retention strategies**.

Built using the **IBM Telco Customer Churn dataset**, this project mirrors **real-world churn analytics workflows** used in telecom and subscription-based businesses.

---

## ğŸš€ Business Problem

Customer churn directly impacts revenue. Retaining an existing customer is **significantly cheaper** than acquiring a new one.

### **Primary Question**

> Which customers are most likely to churn â€” and why?

### **Business Objectives**

* Predict churn with **high recall** to minimize missed at-risk customers
* Identify **behavioral, service, and contract-based churn drivers**
* Enable **proactive retention campaigns**

---

## ğŸ§¾ Dataset Overview

Each row represents a customer; columns represent demographics, services, and billing information.

### Feature Groups

## ğŸ”§ Services**

* PhoneService, MultipleLines
* InternetService
* OnlineSecurity, OnlineBackup
* DeviceProtection, TechSupport
* StreamingTV, StreamingMovies

## ğŸ’³ Account Information**

* tenure
* Contract
* PaymentMethod
* PaperlessBilling
* MonthlyCharges
* TotalCharges

## ğŸ‘¥ Demographics**

* gender
* SeniorCitizen
* Partner
* Dependents

## ğŸ¯ Target**

* `Churn` (Yes / No)

---

## ğŸ—‚ï¸ Project Structure

```text
customer-churn-prediction/
â”‚â”€â”€ artifacts/
â”‚   â”œâ”€â”€model_evaluation_results.json
â”‚   â”œâ”€â”€model_evaluation_results.csv
â”‚   â”œâ”€â”€ evaluation_metrics.json
â”‚   â”œâ”€â”€ classification_report.csv
â”‚   â”œâ”€â”€ confusion_matrix.csv
â”‚   â”œâ”€â”€ decile_lift.csv
â”‚   â””â”€â”€ roc_auc.txt
â”‚   
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ churn_raw.csv
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ churn_clean.csv
â”‚       â”œâ”€â”€ featured_telco.csv
â”‚       â””â”€â”€  retention_targets.csv
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ catboost.joblib
â”‚   â”œâ”€â”€ decision_tree.joblib
â”‚   â”œâ”€â”€ feature_columns.joblib
â”‚   â”œâ”€â”€ lightgbm.joblib
â”‚   â”œâ”€â”€ logistic_regression.joblib
â”‚   â”œâ”€â”€ random_forest.joblib
â”‚   â”œâ”€â”€ xgboost.joblib
â”‚   â”œâ”€â”€ training_metrics.json
â”‚   â”œâ”€â”€ churn_model.joblib
â”‚   â””â”€â”€ churn_pipeline.joblib
â”‚
â”œâ”€â”€ notebooks/
|   â””â”€â”€ catboost_info/
|       â””â”€â”€â”œâ”€â”€ 01_data_understanding.ipynb
â”‚          â”œâ”€â”€ 02_eda.ipynb
â”‚          â”œâ”€â”€ 03_feature_engineering.ipynb
â”‚          â””â”€â”€ 04_model_training.ipynb
â”‚   
â”œâ”€â”€ src/
|   â”œâ”€â”€ _init_.py
â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ predict.py
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figures/
â”‚       â”œâ”€â”€ churn_distribution_pie.png
â”‚       â”œâ”€â”€ contract_churn_barh.png
â”‚       â””â”€â”€ tenure_churn_violin.png
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ main.py
â”œâ”€â”€ README.md
â””â”€â”€ ARCHITECTURE.md

```

---

## ğŸ› ï¸ Tech Stack

* **Language:** Python
* **Data Analysis:** Pandas, NumPy
* **Visualization:** Matplotlib, Seaborn
* **ML Models:** Scikit-learn, XGBoost, LightGBM, CatBoost
* **Imbalance Handling:** Classimbalance weight
* **Explainability:** SHAP
* **Environment:** Jupyter Notebook
* **Version Control:** Git & GitHub

---

## ğŸ”¬ Methodology

### 1ï¸âƒ£ Data Cleaning

* Data type correction (e.g., `TotalCharges`)
* Missing value handling
* Standardized categorical values

### 2ï¸âƒ£ Exploratory Data Analysis

* Overall churn distribution
* Churn vs contract, tenure, monthly charges
* Identification of high-risk segments

### 3ï¸âƒ£ Feature Engineering

* Binary encoding for Yes/No features
* One-hot encoding for categorical variables
* Derived tenure and billing features

### 4ï¸âƒ£ Modeling

* Baselines: Logistic Regression, Decision Tree
* Advanced: Random Forest, XGBoost, LightGBM, CatBoost
* Class imbalance handled using **SMOTE**

### 5ï¸âƒ£ Evaluation

* ROC-AUC
* Precision, Recall, F1-score
* Confusion Matrix

ğŸ“Œ **Business Priority:** Recall for churn class

### 6ï¸âƒ£ Explainability

* SHAP global feature importance
* Individual prediction interpretation

---

## ğŸ“ˆ Key Results & Insights

## Top Churn Drivers**

* Month-to-month contracts
* High monthly charges
* Lack of TechSupport & OnlineSecurity
* Low tenure

**Insight:**
Customers with **short tenure**, **high bills**, and **no support services** show the highest churn probability.

---

## ğŸ’¡ Business Recommendations

* Incentivize contract upgrades for high-risk users
* Bundle support services for churn-prone segments
* Offer loyalty discounts to long-tenure customers
* Trigger targeted retention campaigns using churn scores

---

## â–¶ï¸ How to Run

```bash
git clone <repo-url>
cd customer-churn-prediction
pip install -r requirements.txt
```

Run notebooks in sequence:

---
01 â†’ 02 â†’ 03 â†’ 04 â†’ 05

---

Or train via script:

```bash
python src/train.py
```

---

## ğŸ”® Future Enhancements

* Cost-sensitive churn modeling
* CLV-based retention optimization
* Uplift modeling
* FastAPI inference service
* Streamlit dashboard

---

## ğŸ‘©â€ğŸ’» Author

**Priya Choure**
Data Science & Artificial Intelligence Practitioner
